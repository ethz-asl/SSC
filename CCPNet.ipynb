{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "vC844oIyLwIG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VHz4TlP_Lz-P"
   },
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=1,out_channels=8,kernel_size=3,stride=1,padding=1, dilation=1,groups=1)\n",
    "        self.conv2 = nn.Conv3d(in_channels=8,out_channels=8,kernel_size=3,stride=1,padding=1, dilation=1,groups=1)\n",
    "        self.pool3 = nn.MaxPool3d(3,2,1)\n",
    "        self.diconv4 = nn.Conv3d(in_channels=8,out_channels=16,kernel_size=3,stride=1,padding=2, dilation=2,groups=1)\n",
    "        self.diconv5 = nn.Conv3d(in_channels=16,out_channels=16,kernel_size=3,stride=1,padding=2, dilation=2,groups=4)\n",
    "        self.diconv6 = nn.Conv3d(in_channels=16,out_channels=16,kernel_size=3,stride=1,padding=2, dilation=2,groups=8)\n",
    "        self.pool7 = nn.MaxPool3d(3,2,1)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "      a1= self.conv1(inputs)\n",
    "      a2= self.conv2(a1)\n",
    "      a3= self.pool3(a2)\n",
    "      a4= self.diconv4(a3)\n",
    "      a5=self.diconv5(a4)\n",
    "      a6=self.diconv6(a5)\n",
    "      a7=self.pool7(a6)\n",
    "      return a2, a6, a7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "-C1owmY0qer8"
   },
   "outputs": [],
   "source": [
    "class BRB(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BRB, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=8,out_channels=8,kernel_size=3,stride=1,padding=1, dilation=1,groups=1),\n",
    "            nn.BatchNorm3d(8),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(in_channels=8,out_channels=8,kernel_size=3,stride=1,padding=1, dilation=1,groups=1),\n",
    "            nn.BatchNorm3d(8),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "      a1= self.layers(inputs)\n",
    "      a2= a1 +inputs\n",
    "      a3=nn.functional.relu(a2)\n",
    "      return a3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tLqaNaNcx126"
   },
   "outputs": [],
   "source": [
    "class GRB(torch.nn.Module):\n",
    "    def __init__(self, num_feats=8):\n",
    "        super(GRB, self).__init__()\n",
    "\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=num_feats,out_channels=num_feats,kernel_size=3,stride=1,padding=1, dilation=1,groups=1),\n",
    "            nn.BatchNorm3d(num_feats),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(in_channels=num_feats,out_channels=num_feats,kernel_size=3,stride=1,padding=1, dilation=1,groups=1),\n",
    "            nn.BatchNorm3d(num_feats),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "      a1= self.layers(inputs)\n",
    "      a2= a1 + inputs + (inputs * torch.tanh(inputs)) \n",
    "      a3=nn.functional.relu(a2)\n",
    "      return a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "9wZ7WxpW26XA"
   },
   "outputs": [],
   "source": [
    "class CCP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CCP, self).__init__()\n",
    "\n",
    "        self.diconv1 = nn.Conv3d(in_channels=16,out_channels=16,kernel_size=3,stride=1,padding=30, dilation=30,groups=16)\n",
    "        self.diconv2 = nn.Conv3d(in_channels=16,out_channels=16,kernel_size=3,stride=1,padding=24, dilation=24,groups=16)\n",
    "        self.diconv3 = nn.Conv3d(in_channels=16,out_channels=16,kernel_size=3,stride=1,padding=18, dilation=18,groups=16)\n",
    "        self.diconv4 = nn.Conv3d(in_channels=16,out_channels=16,kernel_size=3,stride=1,padding=12, dilation=12,groups=16)\n",
    "        self.diconv5 = nn.Conv3d(in_channels=16,out_channels=16,kernel_size=3,stride=1,padding=6, dilation=6,groups=16)\n",
    "        self.diconv6 = nn.Conv3d(in_channels=16,out_channels=16,kernel_size=3,stride=1,padding=1, dilation=1,groups=16)\n",
    "        \n",
    "        self.conv1 = nn.Conv3d(in_channels=16,out_channels=8,kernel_size=1,stride=1,padding=0, dilation=1,groups=8)\n",
    "        self.conv2 = nn.Conv3d(in_channels=16,out_channels=8,kernel_size=1,stride=1,padding=0, dilation=1,groups=8)\n",
    "        self.conv3 = nn.Conv3d(in_channels=16,out_channels=8,kernel_size=1,stride=1,padding=0, dilation=1,groups=8)\n",
    "        self.conv4 = nn.Conv3d(in_channels=16,out_channels=8,kernel_size=1,stride=1,padding=0, dilation=1,groups=8)\n",
    "        self.conv5 = nn.Conv3d(in_channels=16,out_channels=8,kernel_size=1,stride=1,padding=0, dilation=1,groups=8)\n",
    "        self.conv6 = nn.Conv3d(in_channels=16,out_channels=8,kernel_size=1,stride=1,padding=0, dilation=1,groups=8)\n",
    "\n",
    "        self.brb2 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=8,out_channels=8,kernel_size=1,stride=1,padding=0, dilation=1,groups=8),\n",
    "            BRB())\n",
    "        self.brb3 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=8,out_channels=8,kernel_size=1,stride=1,padding=0, dilation=1,groups=8),\n",
    "            BRB())\n",
    "        self.brb4 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=8,out_channels=8,kernel_size=1,stride=1,padding=0, dilation=1,groups=8),\n",
    "            BRB())\n",
    "        self.brb5 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=8,out_channels=8,kernel_size=1,stride=1,padding=0, dilation=1,groups=8),\n",
    "            BRB())\n",
    "        self.brb6 = nn.Sequential(\n",
    "            nn.Conv3d(in_channels=8,out_channels=8,kernel_size=1,stride=1,padding=0, dilation=1,groups=8),\n",
    "            BRB())\n",
    "\n",
    "    def forward(self, inputs):\n",
    "      x1 = self.conv1(self.diconv1(inputs))\n",
    "      x2 = self.conv2(self.diconv2(inputs))\n",
    "      x3 = self.conv3(self.diconv3(inputs))\n",
    "      x4 = self.conv4(self.diconv4(inputs))\n",
    "      x5 = self.conv5(self.diconv5(inputs))\n",
    "      x6 = self.conv6(self.diconv6(inputs))\n",
    "      out = self.brb6(self.brb5(self.brb4(self.brb3(self.brb2(x1+ x2) + x3) + x4) + x5) + x6)\n",
    "      return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "TajJf_j8EEyg"
   },
   "outputs": [],
   "source": [
    "class GRR(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GRR, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_channels=8,out_channels=16,kernel_size=1,stride=1,padding=0, dilation=1,groups=8)\n",
    "        \n",
    "        self.block2 = nn.Sequential(\n",
    "            GRB(num_feats=16),\n",
    "            nn.ConvTranspose3d(in_channels=16,out_channels=16,kernel_size=3, stride=2,padding=1, dilation=1,groups=16, output_padding=1),\n",
    "            nn.Conv3d(in_channels=16,out_channels=16,kernel_size=3,stride=1, padding=1, dilation=1,groups=16)\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            GRB(num_feats=16),\n",
    "            nn.ConvTranspose3d(in_channels=16,out_channels=16,kernel_size=3,stride=2,padding=1, dilation=1,groups=16,output_padding=1),\n",
    "            nn.Conv3d(in_channels=16,out_channels=8,kernel_size=3,stride=1,padding=1, dilation=1,groups=1)\n",
    "        )\n",
    "\n",
    "        self.block4 = nn.Sequential(\n",
    "            GRB(num_feats=8),\n",
    "            nn.Conv3d(in_channels=8,out_channels=32,kernel_size=3, stride=1,padding=1, dilation=1,groups=8),\n",
    "            nn.Conv3d(in_channels=32,out_channels=12,kernel_size=3,stride=1,padding=1, dilation=1,groups=4)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, encoded_feats_1x=None, encoded_feats_2x=None, encoded_feats_4x=None):\n",
    "      a1 = self.conv1(inputs)\n",
    "\n",
    "      if encoded_feats_4x is not None:\n",
    "        a1 = a1 + encoded_feats_4x\n",
    "\n",
    "      a2 = self.block2(a1)\n",
    "\n",
    "      if encoded_feats_2x is not None:\n",
    "        a2 = a2 + encoded_feats_2x\n",
    "\n",
    "      a3 = self.block3(a2)\n",
    "\n",
    "      if encoded_feats_1x is not None:\n",
    "        a3 = a3 + encoded_feats_1x\n",
    "\n",
    "      a4 = self.block4(a3)\n",
    "      return a4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "icm2rtpugggG"
   },
   "outputs": [],
   "source": [
    "class CCPNet(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CCPNet, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.ccp = CCP()\n",
    "        self.grr = GRR()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "       #1x, 2x, 4x dowsampled extracted feature volume blocks from original volume\n",
    "      feats_1x, feats_2x, feats_4x = self.encoder(inputs)\n",
    "\n",
    "      # ccp layer for multi scale feature aggregation\n",
    "      mfa = self.ccp(feats_4x)\n",
    "\n",
    "      # guided refinement module. Fuses lower level features from encoder \n",
    "      per_class_voxels = self.grr(mfa, feats_1x, feats_2x, feats_4x)\n",
    "\n",
    "      return per_class_voxels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vEuILiS-ghVD"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eSknV-Mmgese"
   },
   "source": [
    "### Instantiate Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "P-PgKTuzZGV9"
   },
   "outputs": [],
   "source": [
    "enc = Encoder()\n",
    "brb = BRB()\n",
    "grb = GRB()\n",
    "ccp = CCP()\n",
    "grr = GRR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "665r9XscnTDz"
   },
   "source": [
    "####Test individual Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U67m21-BqSKS"
   },
   "source": [
    "#### Test Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7hOSHnWZwIP"
   },
   "outputs": [],
   "source": [
    "inputs = torch.randn(1,1,240,144,240)\n",
    "f1,f2,f4 = enc(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGdPVVoJqV54"
   },
   "source": [
    "#### Test GRR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "laH2bgc9xpny",
    "outputId": "9b9192fa-9432-4010-9404-14e29f48ca64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 240, 144, 240])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs2 = torch.randn(1,8,60,36,60)\n",
    "grr(inputs2,f1,f2,f4).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCki6K_Iqfo9"
   },
   "source": [
    "#### Test CCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fqC4RQS59Tve",
    "outputId": "b784e972-de4e-41c6-8596-1e5016727d60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 60, 36, 60])"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs3 = torch.randn(1,16,60,36,60).cuda()\n",
    "ccp(inputs3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3HtnoFstQWq0"
   },
   "outputs": [],
   "source": [
    "#note;\n",
    "# initialize weights using torch.nn.init.kaiming_uniform_ as mentionend in ccpnet paper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1PwxYr8nY4S"
   },
   "source": [
    "### Test complete Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JuHSNoW1nthA"
   },
   "source": [
    "#### setup network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bXh53r7gndle"
   },
   "outputs": [],
   "source": [
    "ccpnet = CCPNet().cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghEZinKnnzUs"
   },
   "source": [
    "test network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xaa6fll8nxWf"
   },
   "outputs": [],
   "source": [
    "inputs = torch.randn(1,1,240,144,240)\n",
    "semantic_voxels = ccpnet(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMUXUqtLsLAg",
    "outputId": "92eb3f05-ff77-4dfe-e068-34c4a872a134"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 12, 240, 144, 240])"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_voxels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cecMxJOcviWf",
    "outputId": "c46720b7-ac04-48ce-d611-f06f35a7c9dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68172"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in ccpnet.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UM4ZWmc_xv_O",
    "outputId": "59ed6d34-69bd-4ddc-d35b-29d3cc86b3ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pthflops\n",
      "  Downloading pthflops-0.4.1.tar.gz (10 kB)\n",
      "Requirement already satisfied: torch in ./venv/lib/python3.6/site-packages (from pthflops) (1.4.0)\n",
      "Using legacy 'setup.py install' for pthflops, since package 'wheel' is not installed.\n",
      "Installing collected packages: pthflops\n",
      "    Running setup.py install for pthflops ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed pthflops-0.4.1\n",
      "\u001b[33mWARNING: You are using pip version 21.1.2; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/home/mcheem/code/SSC/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pthflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5PfhNZEJx16z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to import torch.fx, you pytorch version may be too old.\n"
     ]
    }
   ],
   "source": [
    "from pthflops import count_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8RDLy4xqx5TQ",
    "outputId": "c89286f2-970e-46a0-8371-95d7f20d7149"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation               OPS           \n",
      "----------------------  ------------  \n",
      "encoder_conv1           1857945600    \n",
      "encoder_conv2           14399078400   \n",
      "encoder_pool3           215654400     \n",
      "encoder_diconv4         3599769600    \n",
      "encoder_diconv5         1808179200    \n",
      "encoder_diconv6         912384000     \n",
      "encoder_pool7           53913600      \n",
      "ccp_diconv1             58060800      \n",
      "ccp_conv1               3110400       \n",
      "ccp_diconv2             58060800      \n",
      "ccp_conv2               3110400       \n",
      "ccp_diconv3             58060800      \n",
      "ccp_conv3               3110400       \n",
      "ccp_diconv4             58060800      \n",
      "ccp_conv4               3110400       \n",
      "ccp_diconv5             58060800      \n",
      "ccp_conv5               3110400       \n",
      "ccp_diconv6             58060800      \n",
      "ccp_conv6               3110400       \n",
      "add                     2073600       \n",
      "ccp_brb2_0              2073600       \n",
      "ccp_brb2_1_layers_0     224985600     \n",
      "ccp_brb2_1_layers_1     2073600       \n",
      "ccp_brb2_1_layers_2     2073600       \n",
      "ccp_brb2_1_layers_3     224985600     \n",
      "ccp_brb2_1_layers_4     2073600       \n",
      "add_1                   2073600       \n",
      "add_2                   2073600       \n",
      "ccp_brb3_0              2073600       \n",
      "ccp_brb3_1_layers_0     224985600     \n",
      "ccp_brb3_1_layers_1     2073600       \n",
      "ccp_brb3_1_layers_2     2073600       \n",
      "ccp_brb3_1_layers_3     224985600     \n",
      "ccp_brb3_1_layers_4     2073600       \n",
      "add_3                   2073600       \n",
      "add_4                   2073600       \n",
      "ccp_brb4_0              2073600       \n",
      "ccp_brb4_1_layers_0     224985600     \n",
      "ccp_brb4_1_layers_1     2073600       \n",
      "ccp_brb4_1_layers_2     2073600       \n",
      "ccp_brb4_1_layers_3     224985600     \n",
      "ccp_brb4_1_layers_4     2073600       \n",
      "add_5                   2073600       \n",
      "add_6                   2073600       \n",
      "ccp_brb5_0              2073600       \n",
      "ccp_brb5_1_layers_0     224985600     \n",
      "ccp_brb5_1_layers_1     2073600       \n",
      "ccp_brb5_1_layers_2     2073600       \n",
      "ccp_brb5_1_layers_3     224985600     \n",
      "ccp_brb5_1_layers_4     2073600       \n",
      "add_7                   2073600       \n",
      "add_8                   2073600       \n",
      "ccp_brb6_0              2073600       \n",
      "ccp_brb6_1_layers_0     224985600     \n",
      "ccp_brb6_1_layers_1     2073600       \n",
      "ccp_brb6_1_layers_2     2073600       \n",
      "ccp_brb6_1_layers_3     224985600     \n",
      "ccp_brb6_1_layers_4     2073600       \n",
      "add_9                   2073600       \n",
      "grr_conv1               4147200       \n",
      "add_10                  4147200       \n",
      "grr_block2_0_layers_0   897868800     \n",
      "grr_block2_0_layers_1   4147200       \n",
      "grr_block2_0_layers_2   4147200       \n",
      "grr_block2_0_layers_3   897868800     \n",
      "grr_block2_0_layers_4   4147200       \n",
      "add_11                  4147200       \n",
      "mul                     4147200       \n",
      "add_12                  4147200       \n",
      "grr_block2_1            464486400     \n",
      "grr_block2_2            464486400     \n",
      "add_13                  33177600      \n",
      "grr_block3_0_layers_0   7182950400    \n",
      "grr_block3_0_layers_1   33177600      \n",
      "grr_block3_0_layers_2   33177600      \n",
      "grr_block3_0_layers_3   7182950400    \n",
      "grr_block3_0_layers_4   33177600      \n",
      "add_14                  33177600      \n",
      "mul_1                   33177600      \n",
      "add_15                  33177600      \n",
      "grr_block3_1            3715891200    \n",
      "grr_block3_2            28731801600   \n",
      "add_16                  132710400     \n",
      "grr_block4_0_layers_0   14399078400   \n",
      "grr_block4_0_layers_1   132710400     \n",
      "grr_block4_0_layers_2   132710400     \n",
      "grr_block4_0_layers_3   14399078400   \n",
      "grr_block4_0_layers_4   132710400     \n",
      "add_17                  132710400     \n",
      "mul_2                   132710400     \n",
      "add_18                  132710400     \n",
      "grr_block4_1            7431782400    \n",
      "grr_block4_2            21598617600   \n",
      "---------------------   -----------   \n",
      "Input size: (1, 1, 240, 144, 240)\n",
      "134,087,270,400 FLOPs or approx. 134.09 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "flops = count_ops(ccpnet, torch.randn(1,1,240,144,240))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ilr0CCoPyyzE",
    "outputId": "d2906efc-fa3b-40ec-c839-2c0e0446072b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134087270400,\n",
       " [['encoder_conv1', 1857945600],\n",
       "  ['encoder_conv2', 14399078400],\n",
       "  ['encoder_pool3', 215654400],\n",
       "  ['encoder_diconv4', 3599769600],\n",
       "  ['encoder_diconv5', 1808179200],\n",
       "  ['encoder_diconv6', 912384000],\n",
       "  ['encoder_pool7', 53913600],\n",
       "  ['ccp_diconv1', 58060800],\n",
       "  ['ccp_conv1', 3110400],\n",
       "  ['ccp_diconv2', 58060800],\n",
       "  ['ccp_conv2', 3110400],\n",
       "  ['ccp_diconv3', 58060800],\n",
       "  ['ccp_conv3', 3110400],\n",
       "  ['ccp_diconv4', 58060800],\n",
       "  ['ccp_conv4', 3110400],\n",
       "  ['ccp_diconv5', 58060800],\n",
       "  ['ccp_conv5', 3110400],\n",
       "  ['ccp_diconv6', 58060800],\n",
       "  ['ccp_conv6', 3110400],\n",
       "  ['add', 2073600],\n",
       "  ['ccp_brb2_0', 2073600],\n",
       "  ['ccp_brb2_1_layers_0', 224985600],\n",
       "  ['ccp_brb2_1_layers_1', 2073600],\n",
       "  ['ccp_brb2_1_layers_2', 2073600],\n",
       "  ['ccp_brb2_1_layers_3', 224985600],\n",
       "  ['ccp_brb2_1_layers_4', 2073600],\n",
       "  ['add_1', 2073600],\n",
       "  ['add_2', 2073600],\n",
       "  ['ccp_brb3_0', 2073600],\n",
       "  ['ccp_brb3_1_layers_0', 224985600],\n",
       "  ['ccp_brb3_1_layers_1', 2073600],\n",
       "  ['ccp_brb3_1_layers_2', 2073600],\n",
       "  ['ccp_brb3_1_layers_3', 224985600],\n",
       "  ['ccp_brb3_1_layers_4', 2073600],\n",
       "  ['add_3', 2073600],\n",
       "  ['add_4', 2073600],\n",
       "  ['ccp_brb4_0', 2073600],\n",
       "  ['ccp_brb4_1_layers_0', 224985600],\n",
       "  ['ccp_brb4_1_layers_1', 2073600],\n",
       "  ['ccp_brb4_1_layers_2', 2073600],\n",
       "  ['ccp_brb4_1_layers_3', 224985600],\n",
       "  ['ccp_brb4_1_layers_4', 2073600],\n",
       "  ['add_5', 2073600],\n",
       "  ['add_6', 2073600],\n",
       "  ['ccp_brb5_0', 2073600],\n",
       "  ['ccp_brb5_1_layers_0', 224985600],\n",
       "  ['ccp_brb5_1_layers_1', 2073600],\n",
       "  ['ccp_brb5_1_layers_2', 2073600],\n",
       "  ['ccp_brb5_1_layers_3', 224985600],\n",
       "  ['ccp_brb5_1_layers_4', 2073600],\n",
       "  ['add_7', 2073600],\n",
       "  ['add_8', 2073600],\n",
       "  ['ccp_brb6_0', 2073600],\n",
       "  ['ccp_brb6_1_layers_0', 224985600],\n",
       "  ['ccp_brb6_1_layers_1', 2073600],\n",
       "  ['ccp_brb6_1_layers_2', 2073600],\n",
       "  ['ccp_brb6_1_layers_3', 224985600],\n",
       "  ['ccp_brb6_1_layers_4', 2073600],\n",
       "  ['add_9', 2073600],\n",
       "  ['grr_conv1', 4147200],\n",
       "  ['add_10', 4147200],\n",
       "  ['grr_block2_0_layers_0', 897868800],\n",
       "  ['grr_block2_0_layers_1', 4147200],\n",
       "  ['grr_block2_0_layers_2', 4147200],\n",
       "  ['grr_block2_0_layers_3', 897868800],\n",
       "  ['grr_block2_0_layers_4', 4147200],\n",
       "  ['add_11', 4147200],\n",
       "  ['mul', 4147200],\n",
       "  ['add_12', 4147200],\n",
       "  ['grr_block2_1', 464486400],\n",
       "  ['grr_block2_2', 464486400],\n",
       "  ['add_13', 33177600],\n",
       "  ['grr_block3_0_layers_0', 7182950400],\n",
       "  ['grr_block3_0_layers_1', 33177600],\n",
       "  ['grr_block3_0_layers_2', 33177600],\n",
       "  ['grr_block3_0_layers_3', 7182950400],\n",
       "  ['grr_block3_0_layers_4', 33177600],\n",
       "  ['add_14', 33177600],\n",
       "  ['mul_1', 33177600],\n",
       "  ['add_15', 33177600],\n",
       "  ['grr_block3_1', 3715891200],\n",
       "  ['grr_block3_2', 28731801600],\n",
       "  ['add_16', 132710400],\n",
       "  ['grr_block4_0_layers_0', 14399078400],\n",
       "  ['grr_block4_0_layers_1', 132710400],\n",
       "  ['grr_block4_0_layers_2', 132710400],\n",
       "  ['grr_block4_0_layers_3', 14399078400],\n",
       "  ['grr_block4_0_layers_4', 132710400],\n",
       "  ['add_17', 132710400],\n",
       "  ['mul_2', 132710400],\n",
       "  ['add_18', 132710400],\n",
       "  ['grr_block4_1', 7431782400],\n",
       "  ['grr_block4_2', 21598617600]])"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flops"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CCPNet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
